# Project 4 - Wine Quality 

## Overview

For Project 4, we undertook the challenge of classifying Red Wine into distinct categories of quality—differentiating between good and bad wine—based on a combination of physiochemical inputs and sensory output variables, leveraging machine learning and other technologies. 

We imported the Wine Dataset into Google Colab using PySpark and further utilized the flexibility of Pandas to execute SQL queries on the dataset. To enhance the robustness of our analysis, we standardized the dataset, ensuring consistency and accuracy in our subsequent steps.

Our machine learning pipeline comprised several sophisticated models, each carefully selected to optimize predictive performance:

Logistic Regression Classifier with the default lbfgs solver
Logistic Regression Classifier with the liblinear solver
Logistic Regression Classifier with the default lbfgs solver and integrated RandomOverSampler
Random Forest Classifier
Support Vector Classifier

Through meticulous application and tuning of these models, we aimed to achieve refined predictions and gain deeper insights into the characteristics that determine wine quality.

## Technologies Used
- Scikit-learn
- [Other machine learning library]

### Additional Technologies
- Python Pandas
- Google Colab
- PySpark
- pyspark.spl
- [Any other technologies used]

## Dataset
Our project is powered by a dataset containing 1600 records. The dataset is focused on kaggle as:(https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009/data)

## Project Requirements
### Data Model Implementation 
- A Python script initializes, trains, and evaluates a model (10 points)
- The data is cleaned, normalized, and standardized prior to modeling (5 points)
- The model utilizes data retrieved from SQL or Spark (5 points)
- The model demonstrates meaningful predictive power at least 75% classification accuracy or 0.80 R-squared. (5 points)

### Data Model Optimization 
- The model optimization and evaluation process showing iterative changes made to the model and the resulting changes in model performance are documented in either a CSV/Excel table or in the Python script itself (15 points)
- Overall model performance is printed or displayed at the end of the script (10 points)

## How to Run
[Provide instructions on how to run your project, including any dependencies and setup steps]

## Results
[Discuss the key results, insights, or findings from your project]

## Future Improvements
[Highlight any areas where the project could be improved or extended in the future]

## Contributors
- [List contributions of each team member] 

## Acknowledgments
[Give credit to any external libraries, resources, or tools you used in your project]

